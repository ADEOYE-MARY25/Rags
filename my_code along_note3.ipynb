{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426e53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c111b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!1\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as  np\n",
    "\n",
    "\n",
    "print(\"Libraries imported successfully!1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43373279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Model loaded!\n",
      "Model produces 384 dimensional embeddings\n"
     ]
    }
   ],
   "source": [
    "# Loaad a small, fast embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "\n",
    "model = SentenceTransformer ('all-MiniLM-L6-v2')\n",
    "print(\"Model loaded!\")\n",
    "print(f\"Model produces {model.get_sentence_embedding_dimension()} dimensional embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feab1ba",
   "metadata": {},
   "source": [
    "Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2dd64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: The cat sat on the met\n",
      "Embedding shape: (384,)\n",
      "Embedding type: <class 'numpy.ndarray'>\n",
      "\n",
      "First 10 values: [ 0.07994752 -0.00066558  0.01172572  0.08463687 -0.10899851  0.02930527\n",
      "  0.01828371  0.00536318 -0.03327654 -0.01049046]\n"
     ]
    }
   ],
   "source": [
    "# Simple example\n",
    "\n",
    "text = \"The cat sat on the met\"\n",
    "\n",
    "# Generate embedding\n",
    "embedding = model.encode(text)\n",
    "\n",
    "print(f\"Original text: {text}\")\n",
    "print(f\"Embedding shape: {embedding.shape}\")\n",
    "print(f\"Embedding type: {type(embedding)}\")\n",
    "print(f\"\\nFirst 10 values: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1138b584",
   "metadata": {},
   "source": [
    "Similarity: The Heart of RAG\n",
    "\n",
    "Cosine Similarity Explained\n",
    "cosine similarity measures how similar two vectors are.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8296c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Similarity function ready!\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    calculate cosine similarity between two vectors\n",
    "    \n",
    "    Returns a score between -1 and 1 (higher = more similar)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product /  (norm1 * norm2)\n",
    "\n",
    "print(\" Similarity function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c60560b",
   "metadata": {},
   "source": [
    "Testing Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33d564d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing to: 'The cat sat on the mat'\n",
      "\n",
      "Similarity to 'The cat sat on the mat'\n",
      "Score: 1.000\n",
      "\n",
      "Similarity to 'A feline rested on the rug'\n",
      "Score: 0.564\n",
      "\n",
      "Similarity to 'Dogs are loyal animals'\n",
      "Score: 0.165\n",
      "\n",
      "Similarity to 'Python is a programming language'\n",
      "Score: 0.031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create test sentences\n",
    "sentences = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"A feline rested on the rug\",      # Similar meaning, different word\n",
    "    \"Dogs are loyal animals\",           # Differnt topic\n",
    "    \"Python is a programming language\"   #completely unrelated\n",
    "]\n",
    "\n",
    "\n",
    "# Generate embeddings for all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Compare first sentence to all others\n",
    "print(\"Comparing to: 'The cat sat on the mat'\\n\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    similarity = cosine_similarity(embeddings[0], embeddings[i])\n",
    "    print(f\"Similarity to '{sentence}'\")\n",
    "    print(f\"Score: {similarity:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952e4c0",
   "metadata": {},
   "source": [
    "Building a Simple Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34535446",
   "metadata": {},
   "source": [
    "Create a Document Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4927415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowlege base: 8 documents\n"
     ]
    }
   ],
   "source": [
    "# Sample Knowledge base\n",
    "documents = [\n",
    "    \"Python is high-level programming language known for simplicity\",\n",
    "    \"Machine learning enables computers to learn from data\",\n",
    "    \"Neural networks are inspired by biological brains\",\n",
    "    \"Dogs are loyal and friendly pets that need exercise\",\n",
    "    \"Cats are independent animals that make grat combinations\",\n",
    "    \"JavaScript is used for web development and runs in browsers\",\n",
    "    \"Deep learning uses multi_layered neural networks\",\n",
    "    \"Puppies require training and socialization from an early age\"\n",
    "]\n",
    "\n",
    "print(f\"Knowlege base: {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7669db3",
   "metadata": {},
   "source": [
    "Embed All Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "049c772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for all documents....\n",
      " Created 8 embeddings\n",
      "Each embeddings has 384 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all documents\n",
    "\n",
    "print(\"Generating embeddings for all documents....\")\n",
    "doc_embeddings = model.encode(documents)\n",
    "\n",
    "print(f\" Created {len(doc_embeddings)} embeddings\")\n",
    "print(f\"Each embeddings has {doc_embeddings[0].shape[0]} dimensions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b7d62",
   "metadata": {},
   "source": [
    "Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf1289b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search function ready!\n"
     ]
    }
   ],
   "source": [
    "def search(query, documents, doc_embeddings, top_k=3):\n",
    "    \"\"\"\n",
    "    Search for documents similar to the query.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        query: Search (string)\n",
    "        documents: LIst of document texts\n",
    "        doc_embeddings: Pre-computed document embeddings\n",
    "        top_k: Number of results to return\n",
    "\n",
    "    Returns:\n",
    "        Lists of  (document, similarity_score) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query)\n",
    "\n",
    "    # Calculate similarities\n",
    "    similarities = []\n",
    "    for i, doc_emb in enumerate(doc_embeddings):\n",
    "        similarity = cosine_similarity(query_embedding, doc_emb)\n",
    "        similarities.append((documents[i], similarity))\n",
    "\n",
    "    # sort by similarity (highest first)\n",
    "    similarities.sort(key=lambda x:x[1], reverse=True)\n",
    " \n",
    "\n",
    "    # Return top k results\n",
    "    return similarities[:top_k]\n",
    "\n",
    "\n",
    "print(\"Search function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ebcc4",
   "metadata": {},
   "source": [
    "## Continuation on Module8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b0df4b",
   "metadata": {},
   "source": [
    "Build complete RAG systems using LangChain's modern LCEL (LangChain Expression Language)\n",
    "\n",
    "\n",
    "Setup\n",
    "Require packages\n",
    "\n",
    "pip install langchain langchain-core langchain-community langchain-openai langchain-text-splitters\n",
    "\n",
    "pip install faiss-cpu python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4adb6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49d5c93f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "OPENAI_API_KEY not found in .env file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m api_key= os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY not found in .env file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mApI key loaded\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: OPENAI_API_KEY not found in .env file"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key= os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
    "\n",
    "print('ApI key loaded')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76c5ff53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 documents\n",
      "First document: LangChain is a framework for developing applications powered by language models.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# create documents directly (you can also load from files using loaders)\n",
    "documents = [\n",
    "\n",
    "     Document(page_content=\"LangChain is a framework for developing applications powered by language models.\"),\n",
    "    Document(page_content=\"RAG combines retrieval with generation to provide accurate, grounded responses.\"),\n",
    "    Document(page_content=\"Vector stores enable efficient similarity search over embedded documents.\"),\n",
    "    Document(page_content=\"FAISS is a library for efficient similarity search developed by Meta AI.\"),\n",
    "    Document(page_content=\"Text splitters chunk documents into smaller pieces for better retrieval.\")\n",
    "]\n",
    "\n",
    "print(f\"Created {len(documents)} documents\")\n",
    "print(f'First document: {documents[0].page_content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4150cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "\n",
    "# Split documents\n",
    "chunks =text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split {len(documents)} documents into {len(chunks)} chunks\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\nChunk {i+1}: {chunk.page_content}\")\n",
    "\n",
    "    chunks= text_splitter.split_documents(documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
